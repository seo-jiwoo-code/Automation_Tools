{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b9548f",
   "metadata": {},
   "source": [
    "# Search for the website of a shopping mall using the Google Search API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02280d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f95d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_website(query):\n",
    "    API_KEY = \"\" \n",
    "    CSE_ID = \"f7180b0c658f4467a\"\n",
    "    \n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"key\": API_KEY,\n",
    "        \"cx\": CSE_ID,\n",
    "        \"num\": 1,\n",
    "        \"fields\": \"items(link)\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(\"https://www.googleapis.com/customsearch/v1\", params=params)\n",
    "    results = response.json()[\"items\"]\n",
    "    \n",
    "    if results:\n",
    "        return results[0][\"link\"]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3fb9f89",
   "metadata": {},
   "source": [
    "# Checking some stuff in the system (necessary installations etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137130da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checking environment \n",
    "# import sys\n",
    "# print(sys.executable)\n",
    "\n",
    "# !pip freeze #see all the installation in the environment \n",
    "\n",
    "# !pip show bs4 #! is for going to the shell environment \n",
    "# !pip install --upgrade bs4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2b167db",
   "metadata": {},
   "source": [
    "# Function that scraps & extracts website info using bs4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52ca4941",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\"Scraping\" refers to the process of gathering data from a website, while \"extracting\" refers to the process of retrieving specific information from the scraped data. In the context of BeautifulSoup (bs4), \"scraping\" would refer to using the library to download the HTML code of a website, while \"extracting\" would refer to using BeautifulSoup's functions to parse through the HTML and pull out specific data points of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#need to adjust this part \n",
    "\n",
    "def get_info(website):\n",
    "    # Code to scrape information from the website\n",
    "    # ...\n",
    "    # Store the information in a dictionary\n",
    "    info = {'website': website, 'email': email, 'phone': phone, 'location': location} #why does it not recognize the email, phone and location? \n",
    "    return info\n",
    "\n",
    "def extract_info(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error: Response status code is\", response.status_code)\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    email = soup.find(\"a\", href=re.compile(\"mailto\")).get_text()\n",
    "    phone = soup.find(\"p\", class_=\"phone\").get_text()\n",
    "    location = soup.find(\"p\", class_=\"location\").get_text()\n",
    "    \n",
    "    # Store the information in a dictionary\n",
    "    info = {'website': website, 'email': email, 'phone': phone, 'location': location}\n",
    "    return info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f002d464",
   "metadata": {},
   "source": [
    "# Function that saves the information to an Excel file using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ec1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(info, filename):\n",
    "    df = pd.DataFrame(info)\n",
    "    df.to_excel(filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "963bdcff",
   "metadata": {},
   "source": [
    "# Final Process: Automation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd027bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the list of shopping malls from an Excel file\n",
    "df = pd.read_excel(\"Shopping_Malls.xlsx\")\n",
    "\n",
    "\n",
    "# Initialize an empty list to store the information\n",
    "all_info = []\n",
    "\n",
    "# Loop over each row in the Excel file\n",
    "for index, row in df.iterrows():\n",
    "    mall_name = row[\"Name\"]\n",
    "    \n",
    "    # Search for the website of the shopping mall\n",
    "    website = search_website(mall_name)\n",
    "    \n",
    "    # If a website was found, extract the information\n",
    "    if website:\n",
    "        info = extract_info(website)\n",
    "        all_info.append(info)\n",
    "        \n",
    "# Save the information to a new Excel file\n",
    "save_to_excel(all_info, \"all_info.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec28c98a28ba2ed18a38fcecdfd860e29d2fa4b20ca69680a4795f251f325b67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
